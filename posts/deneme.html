<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Combined State and Parameter Estimation</title>
  <meta name="description" content="particle filtering, parameter estimation, ">

  <!-- <link rel="stylesheet" href="/css/main.css"> -->
  <link rel="stylesheet" href="../styles/post.css" />

  <script type="text/javascript"
          src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>

    <div class="post">

      <header class="post-header">
        <h1>Quantifying Hacker News with 50 days of data</h1>
        <p class="meta">Nov 27, 2013</p>
      </header>

      <article class="post-content">
      <h3 id="quantifying-hacker-news">Quantifying Hacker News</h3>
    <p>I thought it would be fun to analyze the activity on one of my favorite sources of interesting links and information, <a href="https://news.ycombinator.com/">Hacker News</a>. My source of data is a script I’ve set up some time in August that downloads HN (the Front page and the New stories page) every minute. We will be interested in visualizing the stories as they get upvoted during the day, figuring out which domains/users are most popular, what topics are most popular, and the best time to post a story. I’m making all my data and code (Python data collection scripts + IPython Notebook for analysis) available in case you’d like to carry out a similar analysis.</p>

    <h3 id="data-collection-protocol">Data collection protocol</h3>
    <p>I set up a very simple python script that scrapes the HN <strong>front page</strong> and the <strong>new stories page</strong> every minute. A single day of data begins at 4am (PST) and ends at 4am the next day. The .html files are saved compressed as gzipped pickles and one day occupies roughly 10mb in this format. I had bring down my machine for a few days a few times so there are some gaps in the data, but in the end we get 47 days of data from period between August 22 and October 30.</p>

    <h3 id="raw-html-data-parsing">Raw HTML data parsing</h3>
    <p>The parsing Python script uses <strong>BeautifulSoup</strong> to convert the raw HTML into a more structured JSON. This script was by the way by no means simple to write – HN is based on unstructured tables and I had to discover many strange edge cases in its behavior along the way. At the end I ended up with a 100-line ugliest-parsing-function-ever (really, I’m not proud of it) but it works and outputs something like the following for a single story at a specific snapshot:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="err">'domain':</span><span class="w"> </span><span class="err">u'play.google.com',</span><span class="w"> </span><span class="err">'title':</span><span class="w"> </span><span class="err">u'Nexus</span><span class="w"> </span><span class="err">5',</span><span class="w"> 
    </span><span class="err">'url':</span><span class="w"> </span><span class="err">u'https://play.google.com/store/devices/details?id=nexus_5_black_16gb',</span><span class="w"> 
    </span><span class="err">'num_comments':</span><span class="w"> </span><span class="err">42,</span><span class="w"> </span><span class="err">'rank':</span><span class="w"> </span><span class="err">1,</span><span class="w"> </span><span class="err">'points':</span><span class="w"> </span><span class="err">65,</span><span class="w"> 
    </span><span class="err">'user':</span><span class="w"> </span><span class="err">u'sonier',</span><span class="w"> </span><span class="err">'minutes_ago':</span><span class="w"> </span><span class="err">39,</span><span class="w"> </span><span class="err">'id':</span><span class="w"> </span><span class="err">u'6648519'</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span></code></pre>
    </div>

    <p>We get 60 such entries every minute (30 for front page and 30 for new page) and these are again all saved to disk. We are now ready to bring out the IPython Notebook and get to the juicy analysis!</p>

    <h3 id="the-analysis-detailed-analysis">The Analysis: Detailed analysis</h3>

    <p>Head over to the IPython Notebook <a href="http://cs.stanford.edu/people/karpathy/hn_analysis.html">rendered as HTML</a> for the analysis:</p>

    <p><a href="http://cs.stanford.edu/people/karpathy/hn_analysis.html">
      <img class="aligncenter size-full wp-image-584" title="hn" src="/assets/hn.jpg" width="100%" />
    </a></p>

    <p>Note: I had the entire dataset and .ipynb Ipython Notebook source available for download but recently took it down to save space on my host (sorry).</p>

      </article>

  
  <div id="disqus_thread"></div>
  <script>
  var disqus_shortname = 'ybe-blog';
  var disqus_identifier = 'static-parameter';
      
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                                 
</div>


  </body>

</html>
