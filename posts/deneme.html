
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Combined State and Parameter Estimation</title>
  <meta name="description" content="temporal models, particle filtering, parameter estimation, probabilistic programming">

  <!-- <link rel="stylesheet" href="/css/main.css"> -->
  <link rel="stylesheet" href="../styles/post.css" />


  <script type="text/javascript"
          src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body>

  <div class="post">

  <header class="post-header">
    <p class="home"><a href="/">Home</a></p>
    <p class="home"><a href="/blog.html">Blog&nbsp&nbsp</a></p>
    <p class="post-meta">Nov 28th, 2016</p>
    <h1 class="post-title">Combined State and Parameter Estimation</h1>
  </header>

  <article class="post-content">
    <p>The distinction between <em>models</em> and <em>inference procedures</em> is central to most
introductory presentations of artificial intelligence.  For example: HMMs are a
class of model; the Viterbi algorithm is one associated inference procedure,
the forward–backward algorithm is another, and particle filtering is a third.</p>

<p>Many people describe (and presumably think of) neural networks as a class of
models. I want to argue that this view is misleading, and that it is more useful
to think of neural networks as hopelessly entangled model–inference pairs.
“Model–inference pair” is a mouthful, and there doesn’t seem to be good
existing shorthand, so I will henceforth refer to such objects as “monferences”.
My claim is that we should think of a neural network as an example of a
monference. (An implementation of the Viterbi algorithm, equipped with the
parameters of some <em>fixed</em> HMM, is also a monference.)</p>

<p>I’m about to cite a bunch of existing papers that follow naturally from the
neural-nets-as-monferences perspective—it seems like this idea is already
obvious to a lot of people. But I don’t think it’s been given a name or a
systematic treatment, and I hope others will find what follows as useful
(or at least as deconfounding) as I did.</p>

<hr />

<p>What are the consequences of regarding a neural net as a <em>model</em>?
A personal example is illustrative:</p>

<p>The first time I saw a recurrent neural network, I thought “this is an
interesting model with a broken inference procedure”. A recurrent net looks like
an HMM. An HMM has a discrete hidden state, and a recurrent net has a
vector-valued hidden state.  When we do inference in an HMM, we maintain a
distribution over hidden states consistent with the output, but when we do
inference in a recurrent net, we maintain only a single vector—a single
hypothesis, and a greedy inference procedure. Surely things would be better if
there were some way of modeling uncertainty? Why not treat RNN inference like
Kalman filtering?</p>

<p>This complaint is <em>wrong</em>. Our goal in the remainder of this post is to explore
why it’s wrong.</p>

<hr />


  </article>

      <div id="disqus_thread"></div>
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES * * */
      var disqus_shortname = 'ybe-github';
      var disqus_identifier = 'parameter-estimation';
      
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

    

  </div>                       

</body>
</html>
